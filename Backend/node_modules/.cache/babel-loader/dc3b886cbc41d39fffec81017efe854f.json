{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _objectSpread = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _slicedToArray = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/slicedToArray\");\n\nvar _awaitAsyncGenerator = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\");\n\nvar _wrapAsyncGenerator = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\");\n\nvar _asyncIterator = require(\"C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncIterator\");\n\nconst CID = require('cids');\n\nconst toCamel = require('./lib/object-to-camel');\n\nconst configure = require('./lib/configure');\n\nconst multipartRequest = require('./lib/multipart-request');\n\nconst toUrlSearchParams = require('./lib/to-url-search-params');\n\nconst abortSignal = require('./lib/abort-signal');\n\nconst _require = require('native-abort-controller'),\n      AbortController = _require.AbortController;\n/**\n * @typedef {import('ipfs-utils/src/types').ProgressFn} IPFSUtilsHttpUploadProgressFn\n * @typedef {import('ipfs-core-types/src/root').AddProgressFn} IPFSCoreAddProgressFn\n */\n\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/add-all/index')>}\n   */\n  function addAll(_x) {\n    return _addAll.apply(this, arguments);\n  }\n\n  function _addAll() {\n    _addAll = _wrapAsyncGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(source, options = {}) {\n      var controller, signal, _yield$_awaitAsyncGen, headers, body, total, parts, _ref, _ref2, progressFn, onUploadProgress, res, _iteratorNormalCompletion, _didIteratorError, _iteratorError, _iterator, _step, _value, file;\n\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) switch (_context.prev = _context.next) {\n          case 0:\n            // allow aborting requests on body errors\n            controller = new AbortController();\n            signal = abortSignal(controller.signal, options.signal);\n            _context.next = 4;\n            return _awaitAsyncGenerator(multipartRequest(source, controller, options.headers));\n\n          case 4:\n            _yield$_awaitAsyncGen = _context.sent;\n            headers = _yield$_awaitAsyncGen.headers;\n            body = _yield$_awaitAsyncGen.body;\n            total = _yield$_awaitAsyncGen.total;\n            parts = _yield$_awaitAsyncGen.parts;\n            // In browser response body only starts streaming once upload is\n            // complete, at which point all the progress updates are invalid. If\n            // length of the content is computable we can interpret progress from\n            // `{ total, loaded}` passed to `onUploadProgress` and `multipart.total`\n            // in which case we disable progress updates to be written out.\n            _ref = typeof options.progress === 'function' ? createProgressHandler(total, parts, options.progress) : [undefined, undefined], _ref2 = _slicedToArray(_ref, 2), progressFn = _ref2[0], onUploadProgress = _ref2[1];\n            _context.next = 12;\n            return _awaitAsyncGenerator(api.post('add', {\n              searchParams: toUrlSearchParams(_objectSpread(_objectSpread({\n                'stream-channels': true\n              }, options), {}, {\n                progress: Boolean(progressFn)\n              })),\n              timeout: options.timeout,\n              onUploadProgress,\n              signal,\n              headers,\n              body\n            }));\n\n          case 12:\n            res = _context.sent;\n            _iteratorNormalCompletion = true;\n            _didIteratorError = false;\n            _context.prev = 15;\n            _iterator = _asyncIterator(res.ndjson());\n\n          case 17:\n            _context.next = 19;\n            return _awaitAsyncGenerator(_iterator.next());\n\n          case 19:\n            _step = _context.sent;\n            _iteratorNormalCompletion = _step.done;\n            _context.next = 23;\n            return _awaitAsyncGenerator(_step.value);\n\n          case 23:\n            _value = _context.sent;\n\n            if (_iteratorNormalCompletion) {\n              _context.next = 36;\n              break;\n            }\n\n            file = _value;\n            file = toCamel(file);\n\n            if (!(file.hash !== undefined)) {\n              _context.next = 32;\n              break;\n            }\n\n            _context.next = 30;\n            return toCoreInterface(file);\n\n          case 30:\n            _context.next = 33;\n            break;\n\n          case 32:\n            if (progressFn) {\n              progressFn(file.bytes || 0, file.name);\n            }\n\n          case 33:\n            _iteratorNormalCompletion = true;\n            _context.next = 17;\n            break;\n\n          case 36:\n            _context.next = 42;\n            break;\n\n          case 38:\n            _context.prev = 38;\n            _context.t0 = _context[\"catch\"](15);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n\n          case 42:\n            _context.prev = 42;\n            _context.prev = 43;\n\n            if (!(!_iteratorNormalCompletion && _iterator.return != null)) {\n              _context.next = 47;\n              break;\n            }\n\n            _context.next = 47;\n            return _awaitAsyncGenerator(_iterator.return());\n\n          case 47:\n            _context.prev = 47;\n\n            if (!_didIteratorError) {\n              _context.next = 50;\n              break;\n            }\n\n            throw _iteratorError;\n\n          case 50:\n            return _context.finish(47);\n\n          case 51:\n            return _context.finish(42);\n\n          case 52:\n          case \"end\":\n            return _context.stop();\n        }\n      }, _callee, null, [[15, 38, 42, 52], [43,, 47, 51]]);\n    }));\n    return _addAll.apply(this, arguments);\n  }\n\n  return addAll;\n});\n/**\n * Returns simple progress callback when content length isn't computable or a\n * progress event handler that calculates progress from upload progress events.\n *\n * @param {number} total\n * @param {{name:string, start:number, end:number}[]|null} parts\n * @param {IPFSCoreAddProgressFn} progress\n * @returns {[IPFSCoreAddProgressFn|undefined, IPFSUtilsHttpUploadProgressFn|undefined]}\n */\n\nconst createProgressHandler = (total, parts, progress) => parts ? [undefined, createOnUploadProgress(total, parts, progress)] : [progress, undefined];\n/**\n * Creates a progress handler that interpolates progress from upload progress\n * events and total size of the content that is added.\n *\n * @param {number} size - actual content size\n * @param {{name:string, start:number, end:number}[]} parts\n * @param {IPFSCoreAddProgressFn} progress\n * @returns {IPFSUtilsHttpUploadProgressFn}\n */\n\n\nconst createOnUploadProgress = (size, parts, progress) => {\n  let index = 0;\n  const count = parts.length;\n  return ({\n    loaded,\n    total\n  }) => {\n    // Derive position from the current progress.\n    const position = Math.floor(loaded / total * size);\n\n    while (index < count) {\n      const _parts$index = parts[index],\n            start = _parts$index.start,\n            end = _parts$index.end,\n            name = _parts$index.name; // If within current part range report progress and break the loop\n\n      if (position < end) {\n        progress(position - start, name);\n        break; // If passed current part range report final byte for the chunk and\n        // move to next one.\n      } else {\n        progress(end - start, name);\n        index += 1;\n      }\n    }\n  };\n};\n/**\n * @param {any} input\n * @returns {import('ipfs-core-types/src/files').UnixFSEntry}\n */\n\n\nfunction toCoreInterface({\n  name,\n  hash,\n  size,\n  mode,\n  mtime,\n  mtimeNsecs\n}) {\n  const output = {\n    path: name,\n    cid: new CID(hash),\n    size: parseInt(size)\n  };\n\n  if (mode != null) {\n    output.mode = parseInt(mode, 8);\n  }\n\n  if (mtime != null) {\n    output.mtime = {\n      secs: mtime,\n      nsecs: mtimeNsecs || 0\n    };\n  } // @ts-ignore\n\n\n  return output;\n}","map":{"version":3,"sources":["C:/Users/SAINIK/Desktop/LEARNING BTC/NFT-Auction-Marketplace/node_modules/ipfs-http-client/src/add-all.js"],"names":["CID","require","toCamel","configure","multipartRequest","toUrlSearchParams","abortSignal","AbortController","module","exports","api","addAll","source","options","controller","signal","headers","body","total","parts","progress","createProgressHandler","undefined","progressFn","onUploadProgress","post","searchParams","Boolean","timeout","res","ndjson","file","hash","toCoreInterface","bytes","name","createOnUploadProgress","size","index","count","length","loaded","position","Math","floor","start","end","mode","mtime","mtimeNsecs","output","path","cid","parseInt","secs","nsecs"],"mappings":"AAAA;;;;;;;;;;;;;;AAEA,MAAMA,GAAG,GAAGC,OAAO,CAAC,MAAD,CAAnB;;AACA,MAAMC,OAAO,GAAGD,OAAO,CAAC,uBAAD,CAAvB;;AACA,MAAME,SAAS,GAAGF,OAAO,CAAC,iBAAD,CAAzB;;AACA,MAAMG,gBAAgB,GAAGH,OAAO,CAAC,yBAAD,CAAhC;;AACA,MAAMI,iBAAiB,GAAGJ,OAAO,CAAC,4BAAD,CAAjC;;AACA,MAAMK,WAAW,GAAGL,OAAO,CAAC,oBAAD,CAA3B;;iBAC4BA,OAAO,CAAC,yBAAD,C;MAA3BM,e,YAAAA,e;AAER;AACA;AACA;AACA;;;AAEAC,MAAM,CAACC,OAAP,GAAiBN,SAAS,CAAEO,GAAD,IAAS;AAClC;AACF;AACA;AAHoC,WAIjBC,MAJiB;AAAA;AAAA;;AAAA;AAAA,yEAIlC,iBAAyBC,MAAzB,EAAiCC,OAAO,GAAG,EAA3C;AAAA;;AAAA;AAAA;AAAA;AACE;AACMC,YAAAA,UAFR,GAEqB,IAAIP,eAAJ,EAFrB;AAGQQ,YAAAA,MAHR,GAGiBT,WAAW,CAACQ,UAAU,CAACC,MAAZ,EAAoBF,OAAO,CAACE,MAA5B,CAH5B;AAAA;AAAA,wCAKUX,gBAAgB,CAACQ,MAAD,EAASE,UAAT,EAAqBD,OAAO,CAACG,OAA7B,CAL1B;;AAAA;AAAA;AAIUA,YAAAA,OAJV,yBAIUA,OAJV;AAImBC,YAAAA,IAJnB,yBAImBA,IAJnB;AAIyBC,YAAAA,KAJzB,yBAIyBA,KAJzB;AAIgCC,YAAAA,KAJhC,yBAIgCA,KAJhC;AAOE;AACA;AACA;AACA;AACA;AAXF,mBAYyC,OAAON,OAAO,CAACO,QAAf,KAA4B,UAA5B,GACnCC,qBAAqB,CAACH,KAAD,EAAQC,KAAR,EAAeN,OAAO,CAACO,QAAvB,CADc,GAEnC,CAACE,SAAD,EAAYA,SAAZ,CAdN,mCAYSC,UAZT,aAYqBC,gBAZrB;AAAA;AAAA,wCAgBoBd,GAAG,CAACe,IAAJ,CAAS,KAAT,EAAgB;AAChCC,cAAAA,YAAY,EAAErB,iBAAiB;AAC7B,mCAAmB;AADU,iBAE1BQ,OAF0B;AAG7BO,gBAAAA,QAAQ,EAAEO,OAAO,CAACJ,UAAD;AAHY,iBADC;AAMhCK,cAAAA,OAAO,EAAEf,OAAO,CAACe,OANe;AAOhCJ,cAAAA,gBAPgC;AAQhCT,cAAAA,MARgC;AAShCC,cAAAA,OATgC;AAUhCC,cAAAA;AAVgC,aAAhB,CAhBpB;;AAAA;AAgBQY,YAAAA,GAhBR;AAAA;AAAA;AAAA;AAAA,uCA6ByBA,GAAG,CAACC,MAAJ,EA7BzB;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AA6BiBC,YAAAA,IA7BjB;AA8BIA,YAAAA,IAAI,GAAG7B,OAAO,CAAC6B,IAAD,CAAd;;AA9BJ,kBAgCQA,IAAI,CAACC,IAAL,KAAcV,SAhCtB;AAAA;AAAA;AAAA;;AAAA;AAiCM,mBAAMW,eAAe,CAACF,IAAD,CAArB;;AAjCN;AAAA;AAAA;;AAAA;AAkCW,gBAAIR,UAAJ,EAAgB;AACrBA,cAAAA,UAAU,CAACQ,IAAI,CAACG,KAAL,IAAc,CAAf,EAAkBH,IAAI,CAACI,IAAvB,CAAV;AACD;;AApCL;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAJkC;AAAA;AAAA;;AA2ClC,SAAOxB,MAAP;AACD,CA5CyB,CAA1B;AA8CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAMU,qBAAqB,GAAG,CAACH,KAAD,EAAQC,KAAR,EAAeC,QAAf,KAC5BD,KAAK,GAAG,CAACG,SAAD,EAAYc,sBAAsB,CAAClB,KAAD,EAAQC,KAAR,EAAeC,QAAf,CAAlC,CAAH,GAAiE,CAACA,QAAD,EAAWE,SAAX,CADxE;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMc,sBAAsB,GAAG,CAACC,IAAD,EAAOlB,KAAP,EAAcC,QAAd,KAA2B;AACxD,MAAIkB,KAAK,GAAG,CAAZ;AACA,QAAMC,KAAK,GAAGpB,KAAK,CAACqB,MAApB;AACA,SAAO,CAAC;AAAEC,IAAAA,MAAF;AAAUvB,IAAAA;AAAV,GAAD,KAAuB;AAC5B;AACA,UAAMwB,QAAQ,GAAGC,IAAI,CAACC,KAAL,CAAWH,MAAM,GAAGvB,KAAT,GAAiBmB,IAA5B,CAAjB;;AACA,WAAOC,KAAK,GAAGC,KAAf,EAAsB;AAAA,2BACSpB,KAAK,CAACmB,KAAD,CADd;AAAA,YACZO,KADY,gBACZA,KADY;AAAA,YACLC,GADK,gBACLA,GADK;AAAA,YACAX,IADA,gBACAA,IADA,EAEpB;;AACA,UAAIO,QAAQ,GAAGI,GAAf,EAAoB;AAClB1B,QAAAA,QAAQ,CAACsB,QAAQ,GAAGG,KAAZ,EAAmBV,IAAnB,CAAR;AACA,cAFkB,CAGpB;AACA;AACC,OALD,MAKO;AACLf,QAAAA,QAAQ,CAAC0B,GAAG,GAAGD,KAAP,EAAcV,IAAd,CAAR;AACAG,QAAAA,KAAK,IAAI,CAAT;AACD;AACF;AACF,GAhBD;AAiBD,CApBD;AAsBA;AACA;AACA;AACA;;;AACA,SAASL,eAAT,CAA0B;AAAEE,EAAAA,IAAF;AAAQH,EAAAA,IAAR;AAAcK,EAAAA,IAAd;AAAoBU,EAAAA,IAApB;AAA0BC,EAAAA,KAA1B;AAAiCC,EAAAA;AAAjC,CAA1B,EAAyE;AACvE,QAAMC,MAAM,GAAG;AACbC,IAAAA,IAAI,EAAEhB,IADO;AAEbiB,IAAAA,GAAG,EAAE,IAAIpD,GAAJ,CAAQgC,IAAR,CAFQ;AAGbK,IAAAA,IAAI,EAAEgB,QAAQ,CAAChB,IAAD;AAHD,GAAf;;AAMA,MAAIU,IAAI,IAAI,IAAZ,EAAkB;AAChBG,IAAAA,MAAM,CAACH,IAAP,GAAcM,QAAQ,CAACN,IAAD,EAAO,CAAP,CAAtB;AACD;;AAED,MAAIC,KAAK,IAAI,IAAb,EAAmB;AACjBE,IAAAA,MAAM,CAACF,KAAP,GAAe;AACbM,MAAAA,IAAI,EAAEN,KADO;AAEbO,MAAAA,KAAK,EAAEN,UAAU,IAAI;AAFR,KAAf;AAID,GAhBsE,CAkBvE;;;AACA,SAAOC,MAAP;AACD","sourcesContent":["'use strict'\n\nconst CID = require('cids')\nconst toCamel = require('./lib/object-to-camel')\nconst configure = require('./lib/configure')\nconst multipartRequest = require('./lib/multipart-request')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\nconst abortSignal = require('./lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\n\n/**\n * @typedef {import('ipfs-utils/src/types').ProgressFn} IPFSUtilsHttpUploadProgressFn\n * @typedef {import('ipfs-core-types/src/root').AddProgressFn} IPFSCoreAddProgressFn\n */\n\nmodule.exports = configure((api) => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/add-all/index')>}\n   */\n  async function * addAll (source, options = {}) {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n    const { headers, body, total, parts } =\n      await multipartRequest(source, controller, options.headers)\n\n    // In browser response body only starts streaming once upload is\n    // complete, at which point all the progress updates are invalid. If\n    // length of the content is computable we can interpret progress from\n    // `{ total, loaded}` passed to `onUploadProgress` and `multipart.total`\n    // in which case we disable progress updates to be written out.\n    const [progressFn, onUploadProgress] = typeof options.progress === 'function'\n      ? createProgressHandler(total, parts, options.progress)\n      : [undefined, undefined]\n\n    const res = await api.post('add', {\n      searchParams: toUrlSearchParams({\n        'stream-channels': true,\n        ...options,\n        progress: Boolean(progressFn)\n      }),\n      timeout: options.timeout,\n      onUploadProgress,\n      signal,\n      headers,\n      body\n    })\n\n    for await (let file of res.ndjson()) {\n      file = toCamel(file)\n\n      if (file.hash !== undefined) {\n        yield toCoreInterface(file)\n      } else if (progressFn) {\n        progressFn(file.bytes || 0, file.name)\n      }\n    }\n  }\n  return addAll\n})\n\n/**\n * Returns simple progress callback when content length isn't computable or a\n * progress event handler that calculates progress from upload progress events.\n *\n * @param {number} total\n * @param {{name:string, start:number, end:number}[]|null} parts\n * @param {IPFSCoreAddProgressFn} progress\n * @returns {[IPFSCoreAddProgressFn|undefined, IPFSUtilsHttpUploadProgressFn|undefined]}\n */\nconst createProgressHandler = (total, parts, progress) =>\n  parts ? [undefined, createOnUploadProgress(total, parts, progress)] : [progress, undefined]\n\n/**\n * Creates a progress handler that interpolates progress from upload progress\n * events and total size of the content that is added.\n *\n * @param {number} size - actual content size\n * @param {{name:string, start:number, end:number}[]} parts\n * @param {IPFSCoreAddProgressFn} progress\n * @returns {IPFSUtilsHttpUploadProgressFn}\n */\nconst createOnUploadProgress = (size, parts, progress) => {\n  let index = 0\n  const count = parts.length\n  return ({ loaded, total }) => {\n    // Derive position from the current progress.\n    const position = Math.floor(loaded / total * size)\n    while (index < count) {\n      const { start, end, name } = parts[index]\n      // If within current part range report progress and break the loop\n      if (position < end) {\n        progress(position - start, name)\n        break\n      // If passed current part range report final byte for the chunk and\n      // move to next one.\n      } else {\n        progress(end - start, name)\n        index += 1\n      }\n    }\n  }\n}\n\n/**\n * @param {any} input\n * @returns {import('ipfs-core-types/src/files').UnixFSEntry}\n */\nfunction toCoreInterface ({ name, hash, size, mode, mtime, mtimeNsecs }) {\n  const output = {\n    path: name,\n    cid: new CID(hash),\n    size: parseInt(size)\n  }\n\n  if (mode != null) {\n    output.mode = parseInt(mode, 8)\n  }\n\n  if (mtime != null) {\n    output.mtime = {\n      secs: mtime,\n      nsecs: mtimeNsecs || 0\n    }\n  }\n\n  // @ts-ignore\n  return output\n}\n"]},"metadata":{},"sourceType":"script"}